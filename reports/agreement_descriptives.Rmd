---
output: html_document
---


```{r load_project, message=FALSE}
setwd("/Users/TARDIS/Documents/STUDIES/context_word_seg")
library(ProjectTemplate)
load.project()
```

# General descriptives

## How many utterances in each context?

```{r utt_per_context}
######
# WL #
######
WL <- df_WL %>% 
  mutate_each(funs(ifelse(. > 0, 1, 0)), -utt, -orth, -phon)  # for word list analysis only, make all contexts either 1 or 0 (smoothing over 1.5's from expand_windows)

WL_sum <- data.frame(context = names(colSums(dplyr::select(WL, -utt, -orth, -phon))), n=colSums(dplyr::select(WL, -utt, -orth, -phon))) %>% 
  mutate(method="word lists")
WL_sum %>% 
  select(-method) %>% 
  arrange(desc(n)) %>% 
  kable()

######
# HJ #
######
HJ_sum <- data.frame(context=names(colSums(dplyr::select(df_HJ_bin, -utt, -orth, -phon), na.rm=TRUE)), n=colSums(dplyr::select(df_HJ_bin, -utt, -orth, -phon), na.rm=TRUE)) %>% 
  mutate(method="coder judgments")
HJ_sum %>% 
  select(-method) %>% 
  arrange(desc(n)) %>% 
  kable()

######
# TM #
######
LDA_sum <- data.frame(context=names(colSums(dplyr::select(df_LDA_bin, -utt, -orth, -phon), na.rm=TRUE)), n=colSums(dplyr::select(df_LDA_bin, -utt, -orth, -phon), na.rm=TRUE)) %>% 
  mutate(method="LDA")
LDA_sum %>% 
  select(-method) %>% 
  arrange(desc(n)) %>% 
  kable()

STM_sum <- data.frame(context=names(colSums(dplyr::select(df_STM_bin, -utt, -orth, -phon), na.rm=TRUE)), n=colSums(dplyr::select(df_STM_bin, -utt, -orth, -phon), na.rm=TRUE)) %>% 
  mutate(method="STM")
STM_sum %>% 
  select(-method) %>% 
  arrange(desc(n)) %>% 
  kable()
```

```{r, fig.height=12}
all_sum <- rbind(WL_sum, HJ_sum, LDA_sum, STM_sum)

ggplot(all_sum, aes(y=n, x=reorder(as.factor(context), n))) + 
  geom_bar(stat = 'identity', show.legend = FALSE) + 
  geom_hline(aes(yintercept=nrow(df)), lty=2) + 
  facet_wrap(~method, scales = "free_x", ncol=1) + 
  ggtitle("Number of utterances in each context\ndashed line shows total corpus size")

```

## How many contexts per utterance?

```{r context_per_utt}
######
# WL #
######
WL$N.contexts <- rowSums(dplyr::select(WL, -utt, -orth, -phon))
table(WL$N.contexts)

WL <- extract_contexts(WL)
summary(WL$context) # the number of utterances in each context

length(which(WL$N.contexts > 2)) / length(WL$N.contexts) # percent of corpus with > 2 contexts
length(which(WL$N.contexts == 0)) / length(WL$N.contexts) # percent of corpus with 0 contexts
length(which(WL$N.contexts > 2)) / length(which(WL$N.contexts > 0)) 
length(which(WL$N.contexts > 1)) / length(which(WL$N.contexts > 0)) 


######
# HJ #
######
df_HJ_bin$N.contexts <- rowSums(dplyr::select(df_HJ_bin, -utt, -orth, -phon), na.rm = TRUE)
table(df_HJ_bin$N.contexts)

df_HJ_bin <- extract_contexts(df_HJ_bin)
summary(df_HJ_bin$context) # the number of utterances in each context

length(which(df_HJ_bin$N.contexts > 2)) / length(df_HJ_bin$N.contexts) # percent of corpus with > 2 contexts
length(which(df_HJ_bin$N.contexts == 0)) / length(df_HJ_bin$N.contexts) # percent of corpus with 0 contexts

######
# TM #
######
df_LDA_bin$N.contexts <- rowSums(dplyr::select(df_LDA_bin, -utt, -orth, -phon), na.rm = TRUE)
table(df_LDA_bin$N.contexts)

df_LDA_bin <- extract_contexts(df_LDA_bin)
summary(df_LDA_bin$context) # the number of utterances in each context

length(which(df_LDA_bin$N.contexts > 2)) / length(df_LDA_bin$N.contexts) # percent of corpus with > 2 contexts
length(which(df_LDA_bin$N.contexts == 0)) / length(df_LDA_bin$N.contexts) # percent of corpus with 0 contexts

df_STM_bin$N.contexts <- rowSums(dplyr::select(df_STM_bin, -utt, -orth, -phon), na.rm = TRUE)
table(df_STM_bin$N.contexts)

df_STM_bin <- extract_contexts(df_STM_bin)
summary(df_STM_bin$context) # the number of utterances in each context

length(which(df_STM_bin$N.contexts > 2)) / length(df_STM_bin$N.contexts) # percent of corpus with > 2 contexts
length(which(df_STM_bin$N.contexts == 0)) / length(df_STM_bin$N.contexts) # percent of corpus with 0 contexts

###########
# OVERALL #
###########
wl_contexts <- dplyr::select(WL, utt, N.contexts, context) %>% 
  mutate(method = "word list")
hj_contexts <- dplyr::select(df_HJ_bin, utt, N.contexts, context) %>% 
  mutate(method = "coder judgments")
lda_contexts <- dplyr::select(df_LDA_bin, utt, N.contexts, context) %>% 
  mutate(method = "LDA")
stm_contexts <- dplyr::select(df_STM_bin, utt, N.contexts, context) %>% 
  mutate(method = "STM")

all_methods_counts <- rbind(wl_contexts, hj_contexts, lda_contexts, stm_contexts) %>% 
  count(method, N.contexts) 

ggplot(all_methods_counts, aes(y=n, x=method, fill=as.factor(N.contexts))) + 
  geom_bar(stat = "identity") + 
  labs(title = "Number of contexts tagged per utterance", y="Number of utterances", x = "Context defined by") + 
  scale_fill_discrete(name="Number of contexts")

df_HJ_bin_no_none <- dplyr::select(df_HJ_bin, -none, -N.contexts, -context) 
df_HJ_bin_no_none$N.contexts <- rowSums(dplyr::select(df_HJ_bin_no_none, -utt, -orth, -phon), na.rm = TRUE)
df_HJ_bin_no_none <- extract_contexts(df_HJ_bin_no_none)
  
hj_no_none <- dplyr::select(df_HJ_bin_no_none, utt, N.contexts, context) %>%
  mutate(method = "coder judgments")

all_methods_counts_no_none <- rbind(wl_contexts, hj_no_none, lda_contexts, stm_contexts) %>% 
  count(method, N.contexts) 

ggplot(all_methods_counts_no_none, aes(y=n, x=method, fill=as.factor(N.contexts))) + 
  geom_bar(stat = "identity") + 
  labs(title = "Number of contexts tagged per utterance,\nnot including 'none' for coder judgments", y="Number of utterances", x = "Context defined by") + 
  scale_fill_discrete(name="Number of contexts")
table(hj_contexts$N.contexts)
table(hj_no_none$N.contexts)

```


```{r}
all_methods_context_count <- rbind(wl_contexts, hj_contexts, lda_contexts, stm_contexts) %>% 
  count(method, context)
all_methods_context_count$context <- relevel(all_methods_context_count$context, "none" )
all_methods_context_count$context <- relevel(all_methods_context_count$context, "no context tag" )
all_methods_context_count$context <- relevel(all_methods_context_count$context, "ambiguous" )

ggplot(all_methods_context_count, aes(y=n, x=method, fill=context)) + 
  geom_bar(stat= "identity") + 
  scale_fill_manual(values = c("#0072B2", "#D55E00", "#E69F00", rep("#999999", length(levels(all_methods_context_count$context)) - 3)))
```

Printing context files for sharing with CF:

```{r print_context_files}
all <- rbind(wl_contexts, hj_no_none, lda_contexts, stm_contexts) %>% 
  dplyr::select(utt, context, method) %>% 
  tidyr::extract(utt, into = c("child", "age", "utt.num"), regex = "^([[:alpha:]]{2})([[:digit:]]{2})[.]cha_([[:digit:]]+)$")

all$utt.num <- as.numeric(all$utt.num)
  
all %>% 
  dplyr::filter(method=="word list") %>% 
  tidyr::spread(key=utt.num, value=context) %>% 
  dplyr::select(-method) %>% 
  write.csv("/Users/TARDIS/Dropbox/2_RoseM_TP/context_files/contexts_file_WL.csv", row.names=FALSE)
all %>% 
  dplyr::filter(method=="coder judgments") %>% 
  tidyr::spread(key=utt.num, value=context) %>% 
  dplyr::select(-method) %>% 
  write.csv("/Users/TARDIS/Dropbox/2_RoseM_TP/context_files/contexts_file_HJ.csv", row.names=FALSE)  
all %>% 
  dplyr::filter(method=="LDA") %>% 
  tidyr::spread(key=utt.num, value=context) %>% 
  dplyr::select(-method) %>% 
  write.csv("/Users/TARDIS/Dropbox/2_RoseM_TP/context_files/contexts_file_LDA.csv", row.names=FALSE)
all %>% 
  dplyr::filter(method=="STM") %>% 
  tidyr::spread(key=utt.num, value=context) %>% 
  dplyr::select(-method) %>% 
  write.csv("/Users/TARDIS/Dropbox/2_RoseM_TP/context_files/contexts_file_STM.csv", row.names=FALSE)  
```

## Select context files to use

Dropping "none" codes from HJ.
```{r rop_none_codes}
WL <- WL
HJ <- df_HJ_bin_no_none
LDA <- df_LDA_bin 
STM <- df_STM_bin 
```

## General thoughts
The word list and coder definitions of context naturally produce a skewed distribution of activities, whereas the topic modeling approaches discover a more uniform distribution of activities.
To the extent that the distritbution of activities is naturally skewed (e.g. that a few activities happen very often, and many others happen rarely), topic modeling approaches to identifying activity context may distort reality.

# Word list descriptives

## Frequency of WL key words?

```{r}
contexts <- names(WL_contexts)
WL_context_data <- data.frame(NULL)
for(k in contexts){
  WL_context_data <- rbind(WL_context_data, data.frame(word=WL_contexts[[k]], context=k, stringsAsFactors = FALSE))
}

orth_stream <- paste(df$orth, collapse = " ")
# flag bigrams from WL keywords in orth stream, so they don't get separated
for(w_bar in grep(x = WL_context_data$word, pattern = "_", value=TRUE)){
  w_space <- gsub(x=w_bar, pattern="_", replacement=" ")
  orth_stream <- gsub(x=orth_stream, pattern = w_space, replacement = w_bar)
}

orth_stream <- strsplit(orth_stream, split=" ")[[1]]
orth_stream <- orth_stream[orth_stream != ""]

orth_data <- data.frame(word=orth_stream, stringsAsFactors = FALSE) %>% 
  count(word)

WL_context_data <- left_join(WL_context_data, orth_data, by="word") %>% 
  arrange(context, n)

WL_context_data %>% 
  group_by(context) %>% 
  summarise(total=sum(n, na.rm=TRUE), 
            mean.freq=mean(n, na.rm=TRUE), 
            highest=max(n, na.rm=TRUE),
            which.highest=word[which.max(n)]) %>% 
  kable()
```


# HJ

## What raw coder tags make up each category?

```{r hj_wordle_codes}

```

## What words are associated with each category?

```{r hj_wordle_orth}

```

## Do "none" contexts from HJ match utterances with 0 context codes from WL?

```{r none_and_0context, out.width='50%', out.height='50%'}
df_HJ_none <- df_HJ_bin
df_HJ_none$HJ_none <- ifelse(df_HJ_none$none==1, 1,
                             ifelse(df_HJ_none$none==0, 0, NA))
df_HJ_none <- dplyr::select(df_HJ_none, utt, HJ_none) 

df_WL_0 <- WL
df_WL_0$WL_0 <- ifelse(df_WL_0$N.contexts == 0, 1,
                             ifelse(df_WL_0$N.contexts > 0, 0, NA))
df_WL_0 <- dplyr::select(df_WL_0, utt, WL_0) 

match <- full_join(df_HJ_none, df_WL_0, by="utt") %>% 
  mutate(match = HJ_none + WL_0)
match$match <- ifelse(match$match == 2, 1, 
                      ifelse(match$match < 2, 0, NA))
nrow(df_WL_0); nrow(df_HJ_none); nrow(match)
tab <- xtabs( ~ WL_0 + HJ_none, data = match)

addmargins(tab)
summary(tab)
mosaic(tab)
assocplot(tab)
assocstats(tab)
```

What percent of the "none" context utterances in HJ method are 0 context in WL?
```{r}
sum(match$match, na.rm=TRUE) / sum(match$HJ_none, na.rm=TRUE)
```

What percent of the 0 context utterances in WL method are "none" context in HJ?
```{r}
sum(match$match, na.rm=TRUE) / sum(match$WL_0, na.rm=TRUE)
```

# Topic modeling: LDA
What words are associated with each LDA topic?
```{r lda_topics}
lda$topics
```

```{r lda_wordles}

```


# Topic modeling: STM
What words are associated with each STM topic?
```{r stm_topics}
summary(stm)
```

```{r stm_wordles}

```
